# 2026 年度人工智能工程化转型培训采购需求书
 
## 一、 战略定位与项目背景
本部门正在推行“技术转型核心是人的转型”战略，由 **某银行科技部** 发起，面向 **全行科技人员** 开展人工智能（AI）赋能培训。目前，我行已在 **研发效能**（Copilot、智能评审）及 **智能运维** 等领域取得阶段性成果。在整体演进路径上，正处于由 **“单点式探索”** 向 **“体系化系联”** 跨越的关键周期。本项目旨在引入具备相关领域**深厚实战背景**的供应商，协助我方从“单纯工具应用”向“深度智能协同”跃迁，构建 **“懂业务、精技术、驭智能”** 的全栈式技术人才梯队。

### 1.1 采购目标
1.  **AI 认知启蒙**：让全体科技人员**理解 AI 能做什么、不能做什么**，建立对 AI 工具的正确认知，破除"AI 万能论"与"AI 无用论"两个极端。
2.  **赋能工具掌握**：使各岗位人员**掌握 AI 辅助工作的基本方法**，学会利用 AI 工具（如 GitHub Copilot、Cursor、ChatGPT）提升日常工作效率。
3.  **持续学习起点**：本项目是**系列培训的第一期**，重在"启蒙"与"破冰"，为后续的持续学习和深度应用奠定基础，而非一次性实现全面转型。

---

## 二、 培训对象与能力递进路径

### 2.1 AI 赋能下的能力拓展理念
在 AI Native 研发新范式下，**AI 工具显著降低了学习新技能的门槛，使得各岗位人员有机会拓展自身技能边界**。本项目秉持**"AI 赋能，人人可学"**的理念：无论是初级开发、产品经理、测试工程师还是架构师，都可以借助 AI 工具，学习掌握本岗位以外的技能，从而更好地理解全链路工作流程，提升团队协作效率。

**核心观点**：
*   **降低学习门槛**：AI 工具（如 GitHub Copilot、Cursor、ChatGPT）让非专业开发者也能**学习编写代码**，让初级工程师也能**学习架构设计思维**，但这不意味着可以立即取代专业角色。
*   **能力拓展而非替代**：培训的目标是让各岗位人员**理解 AI 能如何辅助工作**、**掌握 AI 工具的基本使用方法**，从而在日常工作中提升效率，而非要求每个人都成为全栈专家。
*   **统一认知基础**：不再按职级或角色分班，全员接受统一的、渐进式的课程培训，建立对 AI Native 研发的共同认知，便于后续的跨角色协作。
*   **能力递进累积**：课程采用**模块化递进设计**（模块 1 → 模块 2 → ... → 模块 N），学员可根据自身需求和能力选择学习深度，完成不同模块数量的学员自然形成能力分级。

### 2.2 灵活参与机制
*   **全员开放**：所有科技人员（产品、需求、架构、开发、测试、运维）均可报名参加培训，不设职级或角色限制。
*   **前序依赖**：课程模块之间存在**前置依赖关系**（如：学习"AI 辅助编码"需先完成"Spec 驱动开发"模块），学员**不得中间插队**，必须按顺序学习。
*   **灵活退出**：学员可在**任意模块结束后退出**，但需在**培训开始前明确声明计划参与的模块范围**（如：只学习模块 1-3，或学习全部模块）。
*   **能力分级**：根据学员完成的模块数量，自然形成能力分级（这是**学习深度**的体现，而非**岗位能力**的替代）：
    *   **完成模块 1-2**：理解 AI 辅助需求分析与 Spec 编写的基本方法，能在本职工作中尝试使用相关工具。
    *   **完成模块 1-4**：掌握 AI 辅助全链路工作流程（需求+编码+测试），理解端到端交付的全貌，便于跨角色协作。
    *   **完成全部模块**：掌握 AI Native 全链路技能（含 RAG、Agent、ModelOps），对复杂 AI 应用有深入理解，可在团队中承担 AI 技术推广角色。

---

## 三、 服务体系设计要求与核心课程矩阵
供应商提供的服务方案应深度集成 **AI Native 研发新范式**，采用 **"渐进式课程链 + 即学即用"** 模式。课程设计需**按技能递进顺序组织**（从基础到高级），每个模块包含：**理论讲解（≤40%）+ 实战演练（≥60%）**，确保学员在每个模块学习后能够立即应用所学技能。

### 课程设计原则
*   **渐进式递进**：课程模块按技能难度递进组织（模块1 → 模块2 → ... → 模块N），后续模块依赖前置模块的知识基础。
*   **即学即用**：每个模块教学完成后，立即配套实战演练，确保学员掌握实用技能。
*   **灵活参与**：学员可全程参与所有模块，也可在任意模块后退出，但需提前声明学习计划，不得中途插队。

---

### 模块一：AI 辅助需求分析与 Spec 编写（基础模块）
*   **前置要求**：无
*   **培训目标**：掌握 AI 辅助需求分析与结构化 Spec 编写能力
*   **核心内容**：
    1.  **大模型基础认知**：大模型的发展历程、核心能力、行业应用趋势
    2.  **AI 辅助需求分析**：利用 LLM 进行头脑风暴、生成产品概念、痛点分析
    3.  **Spec 驱动开发理念**：理解"人写 Spec，AI 写 Code"的核心工作流
    4.  **Spec 编写实战**：学习将用户故事转化为结构化 Spec 文档，掌握 Spec 模板
*   **实战演练**：为一个独立功能（如"用户信息查询 API"）编写完整 Spec 文档
*   **能力产出**：学员能够独立完成需求分析与 Spec 编写工作

---

### 模块二：AI 辅助编码与代码评审（核心模块）
*   **前置要求**：完成模块一
*   **培训目标**：掌握 AI 辅助代码生成与代码质量检查能力
*   **核心内容**：
    1.  **AI 编码工具使用**：GitHub Copilot、Cursor 等工具的使用方法与技巧
    2.  **Spec 驱动编码实战**：严格遵循 Spec 文档，利用 AI 生成符合规范的代码
    3.  **代码质量检查**：利用 AI 进行代码审查、安全漏洞扫描、性能优化建议
    4.  **代码解读与重构**：利用 AI 快速理解存量代码，进行智能重构
*   **实战演练**：基于模块一的 Spec，利用 AI 生成功能代码并进行质量检查
*   **能力产出**：学员能够利用 AI 工具高效完成代码编写与评审工作

---

### 模块三：AI 驱动的测试自动化（核心模块）
*   **前置要求**：完成模块一、二
*   **培训目标**：掌握 AI 驱动的测试用例生成与自动化测试能力
*   **核心内容**：
    1.  **AI 驱动用例生成**：基于 Spec 和代码，利用 AI 批量生成测试用例（正常、异常、边界）
    2.  **自动化测试脚本编写**：利用 AI 辅助编写 Selenium/Playwright 自动化测试脚本
    3.  **根因分析 (RCA)**：利用 AI 对失败用例的日志进行分析，快速定位 Bug 根因
*   **实战演练**：为模块二的代码生成完整测试用例并编写自动化测试脚本
*   **能力产出**：学员能够独立完成测试设计与自动化测试工作

---

### 模块四：RAG 知识库构建实战（高级模块）
*   **前置要求**：完成模块一、二、三
*   **培训目标**：掌握 RAG 知识库架构设计与实现能力
*   **核心内容**：
    1.  **RAG 架构原理**：检索增强生成（RAG）的工作原理与应用场景
    2.  **数据清洗与向量化**：非结构化数据清洗、分块、向量化处理
    3.  **混合检索优化**：向量检索、关键词检索、混合检索策略
    4.  **检索效果评估**：使用 RAGAS 等工具评估检索质量
*   **实战演练**：构建一个小型 RAG 知识库（如技术文档检索系统）
*   **能力产出**：学员能够设计并实现一个完整的 RAG 知识库系统

---

### 模块五：Agent 编排与智能体开发（高级模块）
*   **前置要求**：完成模块一、二、三、四
*   **培训目标**：掌握 Agent 编排架构与智能体应用开发能力
*   **核心内容**：
    1.  **Agent 架构原理**：智能体的工作原理、工具调用机制
    2.  **Agent 编排实战**：基于 LangChain/AutoGPT 开发智能体应用
    3.  **多智能体协作**：设计多个 Agent 的协作流程
    4.  **Prompt 工程优化**：优化 Agent 的 Prompt，提升任务完成质量
*   **实战演练**：开发一个简单的 Agent 应用（如智能客服 Bot、代码审查助手）
*   **能力产出**：学员能够设计并开发智能体应用

---

### 模块六：ModelOps 与模型微调（专家模块，选修）
*   **前置要求**：完成模块一至五
*   **培训目标**：掌握模型微调与私有化部署能力（仅适用于有深度 AI 需求的学员）
*   **核心内容**：
    1.  **大模型原理深度理解**：Transformer 架构深度解析
    2.  **模型微调实战**：LoRA/QLoRA 微调技术，RAGAS 自动化评估
    3.  **私有化部署**：模型量化、vLLM/TensorRT 推理加速
*   **实战演练**：在简化场景中完成模型微调、评估、部署全流程
*   **能力产出**：学员能够独立完成模型微调与部署工作

---

### 贯穿全程：资产沉淀与 SOP 编写
在整个培训过程中，供应商需协助学员将各模块的实战成果整合成**标准作业资产库**：

1.  **《AI Native 工作流标准操作流程（SOP）》**：
    *   基于各模块实战经验，总结出标准化的工作流程（需求→编码→测试→部署）
    *   包含流程图、工具清单、质量门禁
    *   不少于 20 页，需通过采购方技术委员会评审

2.  **《企业级 Prompt 最佳实践》**：
    *   收集各模块实战中的 Prompt 工程示例（至少 20 个典型场景）
    *   覆盖需求澄清、代码生成、测试用例生成、RAG 检索、Agent 调用等环节

3.  **《Spec 驱动开发规范》**：
    *   提供 Spec 编写规范、模板库（至少 5 种典型需求类型）
    *   质量检查清单，确保 Spec 的完整性、可测试性

4.  **模块化代码资产库**：
    *   将各模块的实战代码整理成代码仓库（Git 格式）
    *   包含 Spec 示例、代码示例、测试脚本、RAG 实现、Agent Demo
    *   每个组件可独立运行，便于复用

---

## 四、 交付成果标准与服务评审基准

### 4.1 核心交付成果清单
供应商在服务履行过程中需按阶段提交以下成果：
1.  **定制化课件体系**：包含讲师课件 (PPT)、学员手册、实战指导书 (Lab Guide)。
2.  **实战环境与代码**：提供开箱即用的实战代码仓库 (Repo) 及配套脱敏实验数据。
3.  **规范与资产**：协助产出《企业级 Prompt 最佳实践》、《Spec 驱动开发规范》、《ModelOps 实施指南》等指导文件。

### 4.2 培训成效评估与实战验收基准
采购方将基于以下维度对服务质量及其产出进行综合评估。**供应商的核心责任是"交付高质量的培训资产与方法论体系"**，验收标准以**实体交付物**为主导，培训过程质量为辅助。

#### 一、核心验收标准（实体资产，总权重 85%）

*   **定制化课件体系（权重 30%）**：
    *   **讲师课件（PPT）**：覆盖所有承诺模块（前置模块、模块一至七），每个模块需包含理论阐述、案例分析、实操演示三部分，总页数不少于500页。
    *   **学员手册**：提供完整的学员学习手册（PDF格式），包含知识要点总结、实验步骤指引、常见问题FAQ，每个核心模块（四至七）不少于30页。
    *   **实战指导书（Lab Guide）**：提供至少10个实验场景的详细操作指南，每个指南需包含：实验目标、环境准备、分步操作、验证方法、故障排除。
    *   **验收标准**：通过采购方技术委员会（不少于3名专家）的**内容完整性评审**（覆盖度≥95%）、**质量评审**（逻辑清晰、无重大技术错误、案例真实可用）、**可复用性评审**（其他讲师可直接使用）。

*   **实验代码与数据资产（权重 25%）**：
    *   **代码仓库（Repo）**：提供开箱即用的实战代码仓库（推荐Git格式），包含但不限于：Spec驱动开发示例代码（≥5个完整案例）、AI辅助测试脚本模板（≥3种场景）、RAG知识库构建代码（≥2个完整实现）、Agent应用Demo（≥3个可运行示例）。
    *   **数据资产**：配套提供**脱敏实验数据集或通用数据集**，确保所有代码示例可在该数据集上运行。
    *   **验收标准**：代码需通过**静态代码扫描**（无严重安全漏洞，工具如SonarQube）、**功能验证**（核心功能可运行，通过率≥90%）、**文档完整性检查**（README、代码注释覆盖率≥70%）。

*   **技术指导文件体系（权重 30%）**：
    *   **《AI Native 工作流标准操作流程（SOP）》**：详细定义"人写Spec，AI写Code"的标准作业流程，包含流程图、各环节输入输出、质量门禁、工具清单，不少于20页。
    *   **《企业级 Prompt 最佳实践》**：涵盖至少20个典型业务场景的Prompt工程示例（如需求澄清、代码生成、测试用例生成、根因分析等），每个示例需包含场景描述、Prompt模板、预期输出、优化技巧。
    *   **《Spec 驱动开发规范》**：提供Spec编写规范、模板库（至少5种典型需求类型）、质量检查清单（Check List）、AI辅助Spec生成指南。
    *   **其他指导文件**：根据4.1节承诺，补充《ModelOps 实施指南》等文件。
    *   **验收标准**：文件需通过采购方技术委员会的**完整性评审**（覆盖关键场景≥90%）、**可操作性评审**（L2工程师可直接使用，实测验证）、**维护性评审**（文档结构清晰，便于后续更新）。

#### 二、辅助验收标准（培训过程质量，总权重 15%）

*   **培训满意度（权重 10%）**：
    *   核心模块（模块四至七）的学员满意度评分（5分制）平均分需达到**4.0及以上**。评分维度包括：讲师专业度、内容实用性、案例贴合度、答疑及时性。
    *   满意度调查需覆盖≥80%参训学员，由采购方独立组织，确保客观性。

*   **工作流可行性演示（权重 5%）**：
    *   在培训结束时，由供应商组织一次**AI Native 工作流**的完整演示（时长≥1小时），演示团队可由供应商讲师或参训学员代表组成。
    *   演示需完整覆盖：需求分析 → Spec编写 → AI辅助代码生成 → 测试用例生成 → 代码评审 的全链路，使用**受控的模拟或脱敏环境**。
    *   验收标准：演示流程完整性（覆盖≥3个核心技术环节）、操作可行性（无重大卡顿或失败）、文档支撑度（演示内容与交付文档一致）。

#### 三、可选增值服务（不计入核心验收）

*   **种子讲师培养**：供应商可在培训过程中协助采购方识别并辅导2-3名内部潜力人员，使其具备承接后续内部培训的能力。该项作为**增值服务**，不作为验收条件，但可作为供应商评价加分项。
*   **后续咨询支持**：供应商可提供一定期限（如3个月）的线上答疑或咨询支持服务，协助采购方在实际应用中遇到的问题。

---

## 五、 供应商准入资质与交付保障要求
1.  **交付团队资质**：主讲人需具备人工智能（AI）/大模型领域一线研发或架构经验，核心团队应具有大型企业（尤其金融或头部互联网）落地实战背景。本项目支持跨领域专家联合组队。
2.  **同类业绩证明**：供应商需提供 **至少 3 个** 在互联网、金融或高科技行业实施过类似全栈 AI 赋能转型项目的成功案例，**优先考虑具有"试点先行、分阶段推广"实施经验的供应商**。
3.  **分阶段交付能力**：供应商需具备 **小范围深度赋能** 与 **内部讲师培养** 的双重交付能力，支持项目的可持续演进，避免外部依赖。
4.  **服务支撑能力**：应确保具备提供 **私有化实训环境部署** 的技术能力，并能基于银行内部统一 AI 研发平台（若已部署）进行培训内容适配。
5.  **安全合规保障**：供应商需签署严格的《数据安全及保密协议》，确保在实战演练中涉及的任何非公开数据得到银行级安全防护。
