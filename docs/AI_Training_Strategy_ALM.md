# 2026 年度人工智能工程化转型培训采购需求书
 
## 一、 战略定位与项目背景
本部门正在推行“技术转型核心是人的转型”战略，由 **某银行科技部** 发起，面向 **全行科技人员** 开展人工智能（AI）赋能培训。目前，我行已在 **研发效能**（Copilot、智能评审）及 **智能运维** 等领域取得阶段性成果。在整体演进路径上，正处于由 **“单点式探索”** 向 **“体系化系联”** 跨越的关键周期。本项目旨在引入具备相关领域 **深厚实战背景** 的供应商，协助我方从 “单纯工具应用” 向 “深度智能协同” 跃迁，构建 **“懂业务、精技术、驭智能”** 的全栈式技术人才梯队。

### 1.1 采购目标
1.  **建立统一的 AI Native 认知基座**：通过全员必修课程，统一 AI 赋能研发的思维逻辑，推动从传统研发向 **Spec 驱动开发（SDD）** 范式转型，消除跨岗位沟通壁垒。
2.  **实现核心角色的岗位能力跃迁**：针对产品、开发、测试、架构及运维等关键角色提供深度赋能，确保各岗位能够熟练运用 AI 工具解决本领域核心痛点（如业务逻辑查漏、代码智能生成、测试自动化、架构推演等）。
3.  **构建标准化的 AI 协同工作流**：将 AI 技术深度嵌入现有研发体系，产出一套可落地、可量化的 **《AI Native 工作流标准操作流程（SOP）》**，实现由“单点探索”向“体系化协同”的跃迁。
4.  **沉淀可复用的数字化培训资产**：在实战演练中同步沉淀符合我行业务背景的 **Prompt 示例库、Spec 模板、示范代码及实验数据集**，为后续内部人才培养与知识传承奠定坚实基础。
---

## 二、 培训架构设计与参与对象

### 2.1 培训架构设计理念
本项目采用 **“共同基础 + 角色分班深化”** 的培训架构，确保全员建立统一的 AI 认知基础，同时针对不同岗位提供深度适配的专业技能提升路径。

**核心设计原则**：
*   **共同基础先行**：所有科技岗位人员均需完成“模块一：AI 辅助需求分析与 Spec 评审”，建立统一的 AI Native 研发认知，理解端到端工作流的起点。
*   **角色靶向深化**：针对产品/需求、开发/测试、架构/运维三大核心路径进行角色化赋能，确保培训内容与实际工作高度贴合。
*   **实战资产驱动**：课程设计采用 **理论讲解（≤40%）+ 实战演练（≥60%）** 模式，强调“即学即用”，通过实战沉淀可复用的标准化作业资产。
*   **确定性风控导向**：在 AI Native 工作流设计中，必须强调 **“确定性定级（域名拓扑映射）”** 优先于 **“概率性检测（RAG/语义）”**，确保金融级合规底线。
*   **跨界选修开放**：允许学员在完成必修路径后跨路径选修感兴趣的模块（如开发人员选修产品设计模块），促进跨角色理解与协作。

### 2.2 培训对象分类与路径规划

#### 阶段 1：全员必修 - 统一认知基础
*   **参与对象**：全体科技人员（产品、需求、架构、开发、测试、运维）。
*   **核心课程**：模块一（AI 辅助需求分析与 Spec 评审）。
*   **培训目标**：掌握 Spec 驱动开发（SDD）基本理念，理解“人工输入 → AI 辅助评审 → 人确认为 Spec”的标准流。

#### 阶段 2：角色深化 - 岗位技能跃迁
学员在完成模块一后，根据具体岗位选择以下深化路径：

**路径 A：产品/需求岗位深化**
*   **目标**：利用 AI 提升业务逻辑深度、需求分析效率与 PRD 质量。
*   **关键产出**：结构化、无歧义的业务规格说明书。

**路径 B：开发/测试岗位深化**
*   **目标**：掌握 AI 辅助编码、智能代码评审及 AI 驱动的测试自动化。
*   **关键产出**：通过 AI 质量把关的功能代码与自动化测试脚本。

**路径 C：架构/运维岗位深化**
*   **目标**：利用 AI 辅助架构设计、技术选型决策及智能化运维监控。
*   **关键产出**：AI 优化的技术架构图、选型评估报告及 ModelOps 方案。

### 2.3 灵活参与与能力分级机制
*   **必选结合**：模块一为必修，后续路径模块支持按需报名，各路径单独开班。
*   **能力分级认证**：根据学员完成的模块维度，自然形成“基础认知级”、“岗位专项级”与“跨界复合级”三级 AI 能力画像，作为内部人才选拔的参考。

---

## 三、 核心课程矩阵与内容详述
供应商应基于上述架构，提供包含但不限于以下模块的教学设计与实战环境。

### 3.1 全员必修：模块一 - AI 辅助需求分析与 Spec 评审
*   **培训目标**：掌握利用 AI 工具对需求文档进行“评审、质询、补全”的能力。
*   **详细内容**：
    1.  **大模型基础认知**：LLM 发展历程、核心能力边界及在银行研发效能中的地位。
    2.  **AI 辅助需求评审**：利用 AI 扮演“挑剔的架构师”，识别 PRD 初稿中的逻辑漏洞。
    3.  **Spec 驱动开发理念**：深度理解“SDD 工作流”，掌握从模糊意图到结构化描述的转变。
    4.  **分层防御机制（Layered Defense）**：掌握 **“物理领域划分（确定性定级）+ 风险语义拦截（补充校验）+ 人工专家审计”** 的三层防御架构，理解 AI 在其中的位置。
    5.  **AI 辅助 Spec 结构化**：学习利用 Prompt 将自然语言需求转换为 Gherkin/OpenAPI 等标准化 Spec。
*   **实战演练**：基于提供的“缺陷 PRD 案例”，利用 AI 工具产出符合评审要求的结构化 Spec。

### 3.2 路径 A：产品/需求岗位深化

#### 模块 A1：AI 赋能需求精炼与逻辑优化
*   **培训目标**：利用 AI 提升业务逻辑表达深度，产出高质量的 **[结构化业务规格书]**。
*   **详细内容**：
    1.  **逻辑查漏与边界补全**：利用 AI 进行苏格拉底式提问，自动补全业务异常场景。
    2.  **业务逻辑结构化清洗**：将口语化的需求转化为逻辑清晰的原子化列表。
    3.  **高质量输入技巧**：掌握减少 AI 理解噪音的 Prompt 策略，提升辅助产出准确率。
*   **实战演练**：完成从需求初稿到 **[可交付给技术团队的规格书]** 的端到端优化。

#### 模块 A2：AI 辅助业务流程优化（选修）
*   **培训目标**：掌握利用 AI 进行流程分析、挖掘与优化的工程化方法。
*   **详细内容**：
    1.  **流程挖掘与分析**：利用 AI 识别现有业务路径中的低效环节与瓶颈。
    2.  **决策支持与规则提取**：从海量文档中自动提取业务规则库。
*   **实战演练**：分析现有业务流程，生成具备落地可行性的流程优化方案。
---

### 3.3 路径 B：开发/测试岗位深化

#### 模块 B1：AI 辅助编码与智能评审
*   **培训目标**：掌握 Spec 驱动下的 AI 辅助代码生成与质量把控能力。
*   **详细内容**：
    1.  **AI 编码工具簇实战**：Qoder、通义灵码、TRAE 等工具集成与进阶技巧。
    2.  **从 Spec 到 Code 的映射**：学习如何通过 AI 严格执行规格书定义的逻辑，减少开发偏离。
    3.  **智能重构与漏洞扫描**：利用 AI 快速识别存量代码漏洞，并输出重构建议。
*   **实战演练**：基于模块一产出的 Spec，利用选定工具完成模块化代码编写与 CR。

#### 模块 B2：AI 驱动的测试自动化与 RCA
*   **培训目标**：掌握 AI 生成高质量测试资产与根因分析（RCA）的方法。
*   **详细内容**：
    1.  **智能测试用例设计**：基于 Spec 自动生成全覆盖（正常、异常、边界）的用例。
    2.  **自动化脚本辅助编写**：利用 AI 快速产出 Selenium/Playwright 框架下的测试脚本。
    3.  **基于日志的故障诊断**：利用 AI 分析失败日志，缩短定位 Bug 的时间。
*   **实战演练**：为练习模块产出的代码进行自动化测试闭环，并分析特定注入故障。

#### 模块 B3：专家级 AI 应用 - RAG 与 Agent 开发（选修）
*   **培训目标**：具备构建企业内部专用 AI 应用的技术底座能力。
*   **详细内容**：
    1.  **RAG 架构深度实践**：掌握数据清洗、向量化、混合检索优化等全链路技术，将 RAG 作为高性能的 **[内容辅助生成引擎]** 而非安全决策依据。
    2.  **Agent 角色编排**：设计具有工具调用与自我修正能力的智能体应用。
*   **实战演练**：搭建一个简单的技术文档检索系统或自动化运维 Bot。
---

### 3.4 路径 C：架构/运维岗位深化

#### 模块 C1：AI 辅助架构设计与选型评估
*   **培训目标**：利用 AI 辅助系统演进建议与架构资产管理。
*   **详细内容**：
    1.  **架构图智能映射**：由 Spec 自动辅助推演系统架构图、数据流图。
    2.  **技术决策辅助**：基于多维评估模型，利用 AI 进行技术选型的利弊分析与风险预测。
    3.  **RAG 架构专家级调优**：针对海量技术文档的检索增强架构设计。
*   **实战演练**：为一个业务场景重新设计混合云架构，并输出详细的技术架构方案。

#### 模块 C2：ModelOps 与模型微调概论（选修）
*   **培训目标**：了解模型微调生命周期管理与私有化部署架构。
*   **详细内容**：
    1.  **模型微调实战流程**：从 QLoRA 微调技术到 RAGAS 自动评估的全过程。
    2.  **生产级部署与监控**：探讨私有化部署下的推理加速与效能监控方案。
*   **实战演练**：在模拟环境中体验特定垂直场景模型的微调评估流程。

---

### 3.5 资产沉淀机制：全贯穿模式

1.  **《AI Native 工作流标准操作流程（SOP）》及配套集成包**：
    *   基于各模块实战经验，总结出标准化的工作流程（需求→编码→测试→部署）
    *   包含流程图、工具清单、质量门禁
    *   **《AI应用风险定级与分层防御操作指引》**：将附录A的规则转化为可执行的 Checklist 和决策树图。
    *   **《最小可行集成包（MVP）》**：提供与行内指定平台（Jira/GitLab）集成的自动化脚本、Webhook 配置示例或 API 调用样例，确保 SOP 不是纸上谈兵。
    *   不少于 25 页，集成包需在测试环境演示成功，需通过采购方技术委员会评审

2.  **《企业级 Prompt 最佳实践》**：
    *   收集各模块实战中的 Prompt 工程示例（至少 20 个典型场景）
    *   覆盖需求澄清、代码生成、测试用例生成、RAG 检索、Agent 调用等环节
    *   包含 **[分层防御三级提示词模板]**（定级、增强、审核）

3.  **《智能研发工具包》**：
    *   **典型场景 Prompt 库**：包含需求分析、漏洞扫描、单元测试等实战场景。
    *   **AI 辅助质量检查单**：利用 AI 进行交付物自检的 Checklist。
4.  **模块化代码资产库**：
    *   将各模块的实战代码整理成代码仓库（Git 格式）
    *   包含 Spec 示例、代码示例、测试脚本、RAG 实现、Agent Demo
    *   每个组件可独立运行，便于复用

---

## 四、 交付成果标准与服务评审基准

### 4.1 核心交付成果清单
供应商在服务履行过程中需按阶段提交以下成果：
1.  **培训课件与资料**：包含讲师课件 (PPT)、学员手册、实战演示案例（Live Demo）。
2.  **示范代码与数据**：提供教学用示范代码库（Spec 示例、AI 辅助代码示例、测试脚本示例、简单 RAG Demo 等）及配套实验数据。
3.  **参考指导文档**：提供《AI工具使用快速入门指南》、《Prompt工程基础示例集》、《Spec编写入门模板》等参考资料，供学员后续学习使用。

### 4.2 培训成效评估与验收基准
采购方将基于以下维度对服务质量及其产出进行综合评估。**供应商的核心责任是 “交付高质量的培训课程与示范资产”**，本项目作为 **系列培训第一期**，验收标准聚焦于 **培训过程质量** 与 **基础示范资产**。

#### 4.2.1 培训交付质量（总权重 60%）

*   **课件与教学资料（权重 15%）**：
    *   **讲师课件（PPT）**：覆盖所有承诺模块（全员必修模块 + 三条深化路径的所有模块），每个模块需包含：理论讲解、工具演示、实战案例三部分。
    *   **学员手册**：提供学员学习手册（PDF格式），包含知识要点总结、工具使用指引、实验步骤说明。
    *   **实战演示（Live Demo）**：每个路径的核心模块需包含至少 1个完整的现场演示案例，展示 AI 工具在特定岗位场景下的实际使用效果。
    *   **验收标准**：课件逻辑清晰、内容准确、演示可复现，通过采购方评审（无重大技术错误或误解性内容）。

*   **核心战略理念传递准确性（权重 25%）**：
    *   **各模块课件方案评审**：评估供应商对“Spec驱动开发（SDD）”和“确定性风控”两大核心理念的教学设计质量。
    *   **SOP 沙盘推演考核（关键项）**：学员需分组使用交付的 SOP 草案，对包含高、中、低风险场景的综合案例进行端到端推演，100% 触发正确风险闸口为合格。
    *   **学员知识点掌握度**：培训结束后对学员进行专项知识点测试（涵盖 SDD 范式与分层防御规则），通过率需达到 85% 以上。

*   **培训过程质量（权重 20%）**：
    *   **学员满意度**：培训整体满意度评分（5 分制）需达到 **4.0 及以上**。评分维度包括：讲师专业度、内容实用性、案例贴合度、答疑及时性。
    *   **参与度**：学员出勤率需达到 **80% 以上**（针对已报名学员），实战环节参与度需达到 **70% 以上**。
    *   **效果评估**：培训结束后，通过简单的问卷或访谈，了解学员对AI工具的认知提升情况（是否理解AI能做什么、不能做什么；是否愿意在工作中尝试使用AI工具）。

#### 4.2.2 SOP 工程化质量评审（总权重 25%）
此项重点关注培训后**“学员实战转化率”**与**“示范 SOP 的教学一致性”**。

*   **学员毕业设计评估（15%）**：验收通过率需达到 **85%**。由采购方随机抽取学员小组，在导师指导下使用交付的 SOP 完成一份端到端实战项目（含定级、Spec 设计、代码生成、拦截测试）。专家组依据《毕业设计评价量表》判定合格。
*   **教学一致性拦截演示（10%）**：供应商需演示示范 SOP 在 Staging 环境下的拦截能力。验证依据 **附录 B：《AI Native SOP 教学演示与能力评估基准》**。重点验证 SOP 能否准确将附录 A 的规则转化为教学案例。
*   **技术与商务保障闭环**：
    *   **共识失败退出机制**：若因供应商原因导致 T+10 对齐失败且无法执行默认附录 B 的教学基准，采购方保留无责终止合同并追索赔偿的权利。
    *   **最终仲裁**：涉及技术分歧首启动“前置合理性审查”；仍无法解决则委托 CNAS 机构。

#### 4.2.3 示范资产与参考资料（总权重 15%）

*   **代码示例与案例库（权重 10%）**：
    *   **代码示例**：提供各模块的示范代码片段，仅作为教学参考，无需达到生产级质量。
    *   **数据资产**：配套提供脱敏实验数据集，确保示例可运行。
*   **参考指导文档（权重 5%）**：
    *   包含《AI 工具入门指南》、《Prompt 工程示例集》、《Spec 编写模板》等。

#### 4.2.4 可选增值服务（不计入核心验收）

*   **培训后答疑支持**：供应商可提供培训结束后1-2个月的线上答疑服务（如邮件、企业微信群），协助学员解决在实际工作中遇到的AI工具使用问题。
*   **内部讲师培养**：供应商可在培训过程中协助采购方识别1-2名有潜力的内部人员，提供额外辅导，为后续内部培训做准备。

---

## 五、 供应商准入资质与交付保障要求

### 5.1 基本资质要求
1.  **交付团队资质**：主讲人需具备人工智能（AI）/大模型领域一线研发 or 架构经验，核心团队应具有大型企业（尤其金融或头部互联网）落地实战背景。本项目支持跨领域专家联合组队。
2.  **同类业绩证明**：供应商需提供 **至少 3 个** 在互联网、金融或高科技行业实施过类似 AI 赋能培训项目的成功案例。
3.  **技术响应文件要求（必选）**：供应商在投标阶段必须提交一份基于本需求书（特别是 4.2.2 节及附录 A）的 **《承诺验收测试方案》**。该方案将作为合同技术附件，具有法律约束力。
4.  **《承诺验收测试方案》质量要求（关键项）**：方案必须包含至少 3 个针对【附录 A】的具体测试场景（高、中、低风险各一例），明确定义“输出数据、预期输出及验证方法”。所有验收项必须为可量化、可客观验证的指标。未满足此要求的方案将被判定为“未实质性响应”导致废标。
5.  **基线认可声明**：供应商需在投标时明确声明接受 **附录 B：《MVP Baseline》** 作为潜在的默认验收基准，并可针对其中条款提出优化建议。
6.  **分阶段交付能力**：供应商需具备培训课程设计与内部讲师辅导的能力。

### 5.2 服务保障要求
1.  **服务支撑能力**：应确保具备提供培训环境部署的技术能力，并能基于银行内部统一 AI 研发平台（若已部署）进行培训内容适配。
2.  **环境基线与责任隔离（必选项）**：在部署前，供应商需提供《MVP 环境依赖清单》。采购方需在收到清单后 **3 个工作日内** 确认环境满足该基线要求。因基线不满足导致的部署问题由采购方负责；在基线满足后出现的交付缺陷由供应商承担全责（功能完备性、安全性及稳定性）。
3.  **案例贴合度**：实战演练案例需结合金融业务场景（如信贷、转账、理财等）。
4.  **安全合规保障**：供应商需签署严格的《数据安全及保密协议》，确保在实战演练中涉及的任何非公开数据得到银行级安全防护。

### 5.3 商业合作原则
1.  **共识优先原则**：本项目遵循 **“共识优先于权威，过程对齐优于事后对抗”** 的原则。
2.  **验收标准共创机制（Week 1）**：项目启动后第一周，供应商需与采购方技术委员会共同举办“验收标准对齐工作坊”，将本需求书 4.2.2 节的要求细化为双方认可的《毕业设计评价量表（Rubric）》。该细则一经签署，即作为合同附件。

### 5.4 风险熔断与兜底机制
若供应商提交的《承诺验收测试方案》经采购方评测，被认定为 **偏离附录 B（MVP Baseline）核心基准 20% 以上**，或其提出的通过标准显著低于附录 B 定义的客观指标，采购方有权在授标签约前启动风险熔断，直接取消该供应商的中标资格。

---

## 附录 A：AI 应用风险定级映射表（培训示例）
为了使供应商能够准确理解并传递“确定性定级”与“分层防御”原则，本项目的实战案例与教学内容应基于以下预设规则进行设计：

### A.1 业务域分类与风险预设
| 业务域示例     | 典型子系统/模块                      | 预设风险等级        | 核心特征说明                               |
| :------------- | :----------------------------------- | :------------------ | :----------------------------------------- |
| **核心交易域** | 跨境汇款、信贷审批逻辑、资金清算     | **高风险 / 关键域** | 直接涉及资金流转、敏感数据或关键业务决策。 |
| **客户信息域** | 个人隐私查询、反洗钱审计、风险画像   | **中风险**          | 涉及敏感个人信息或合规审计流程。           |
| **内部办公域** | 会议室预订、知识库查询、内部报表生成 | **低风险**          | 非敏感、非关键业务支持流程。               |

### A.2 分层防御（Layered Defense）触发规则
| 风险等级   | 第一层：确定性定级                       | 第二层：风险语义拦截                               | 第三层：人工专家审计                               |
| :--------- | :--------------------------------------- | :------------------------------------------------- | :------------------------------------------------- |
| **低风险** | 自动识别为 L2 级，允许全面 AI 生成。     | 执行基础关键词过滤。                               | 无需强制审计，由开发者复核即可。                   |
| **中风险** | 识别为 L1 级，AI 生成受限。              | **增强型语义拦截**：重点识别逻辑漏洞与隐私合规性。 | 实战中必须包含“双人复核”环节（Peer Review）。      |
| **高风险** | **强制锁定为 L0 级**，严禁 AI 独立生成。 | 全量合规扫描 + AI 异常行为检测。                   | **强制专家闭环**：Spec 必须由 Tech Lead 签署确认。 |

## 附录 B：AI Native SOP 教学演示与能力评估基准
本基准用于检验教学内容的**“逻辑一致性”**与**“教学有效性”**。

### B.1 教学演示场景（用于检验 SOP 完整性）
| 验证维度       | 演示案例（需模拟附录 A 逻辑）                                             | 预期教学输出                                        |
| :------------- | :------------------------------------------------------------------------ | :-------------------------------------------------- |
| **逻辑强制性** | **高风险域拦截演示**。模拟在核心交易模块未签署 Spec 时的代码报错。        | 学员需能识别拦截触发点，并准确执行“Spec 复核”流程。 |
| **风险判别力** | **混合场景定级演示**。提供包含隐私字段与普通业务逻辑的需求描述。          | 手册/脚本需能清晰引导学员判定风险等级（L0/L1/L2）。 |
| **防御深度**   | **人工专家审计演示**。展示在中高风险场景下，Spec 必须包含的“分层检查项”。 | 学员能产出符合合规要求的《Tech Lead 复核单》。      |

### B.2 能力评估标准（Rubric 要素）
1.  **工具掌握度**：学员是否能熟练使用 SOP 配套的拦截与校验工具。
2.  **规则内化度**：学员是否能独立复刻“附录 A”三层防御逻辑到新业务场景中。
3.  **合规意识**：毕业设计中是否出现绕过 L0 锁定的违规生成行为（一票否决）。
